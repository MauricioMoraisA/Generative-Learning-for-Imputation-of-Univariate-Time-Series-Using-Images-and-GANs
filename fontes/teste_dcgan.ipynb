{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 channels: Iniciando o teste ....\n",
      "2 channels: Iniciando o teste ....\n",
      "3 channels: Iniciando o teste ....\n",
      "0.00945029358069102 horas\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, mean_absolute_percentage_error as mape\n",
    "import numpy as np\n",
    "# Batch size during training\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def asmape(y_true, y_pred, mask=None):\n",
    "    if mask is not None:\n",
    "         y_true, y_pred = y_true[mask==1], y_pred[mask==1]\n",
    "    if type(y_true) is list or type(y_pred) is list:\n",
    "         y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    len_ = len(y_true)\n",
    "    tmp = 100 * (np.nansum(np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))/len_)\n",
    "\n",
    "    return tmp\n",
    "\n",
    "\n",
    "\n",
    "class LoaderDataset(Dataset):\n",
    "    def __init__(self, root_zebra, root_horse, root_masks, chanels=3):\n",
    "        self.root_zebra = root_zebra\n",
    "        self.root_horse = root_horse\n",
    "        self.root_index = root_masks\n",
    "        \n",
    "        self.zebra_images = sorted(os.listdir(root_zebra))\n",
    "        self.horse_images = sorted(os.listdir(root_horse))\n",
    "        self.index = sorted(os.listdir(root_masks))\n",
    "\n",
    "        self.length_dataset = max(len(self.zebra_images), len(self.horse_images))\n",
    "        self.zebra_len = len(self.zebra_images)\n",
    "        self.horse_len = len(self.horse_images)\n",
    "        self.index_len = len(self.index)\n",
    "        self.chanels = chanels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length_dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def custom_normalize(image):\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        min_val = torch.min(image)\n",
    "        max_val = torch.max(image)\n",
    "        scale = torch.clamp(max_val - min_val, min=1e-5)  # Evita divisão por zero\n",
    "        image_normalized = 2 * (image - min_val) / scale - 1  # Escala para [-1, 1]\n",
    "        return image_normalized, min_val, max_val\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        zebra_img = self.zebra_images[index % self.zebra_len]\n",
    "        horse_img = self.horse_images[index % self.horse_len]\n",
    "        index_ids = self.index[index % self.index_len]\n",
    "\n",
    "        zebra_path = os.path.join(self.root_zebra, zebra_img)\n",
    "        horse_path = os.path.join(self.root_horse, horse_img)\n",
    "        index_path = os.path.join(self.root_index, index_ids)\n",
    "        # print(zebra_path, horse_path, index_path)\n",
    "\n",
    "        zebra_img = np.load(zebra_path)\n",
    "        horse_img = np.load(horse_path)\n",
    "        mask = np.load(index_path)\n",
    "\n",
    "        if len(zebra_img.shape) > 3:\n",
    "            zebra_img = zebra_img.reshape(32, 32, 3)\n",
    "            horse_img = horse_img.reshape(32, 32, 3)\n",
    "\n",
    "        zebra_img = np.transpose(zebra_img, (2, 0, 1))\n",
    "        horse_img = np.transpose(horse_img, (2, 0, 1))\n",
    "\n",
    "        if self.chanels == 2:\n",
    "            zebra_img = zebra_img[:2, :, :]\n",
    "            horse_img = horse_img[:2, :, :]\n",
    "        elif self.chanels == 1:\n",
    "            zebra_img = np.sum(zebra_img, axis=0, keepdims=True)\n",
    "            horse_img = np.sum(horse_img, axis=0, keepdims=True)\n",
    "\n",
    "        zebra_img, min_val_z, max_val_z = LoaderDataset.custom_normalize(zebra_img)\n",
    "        horse_img, _, _ = LoaderDataset.custom_normalize(horse_img)\n",
    "\n",
    "        mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "        return zebra_img, horse_img.flatten(), min_val_z, max_val_z, mask\n",
    "    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=3072, ngf=32, nc=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.nz = nz\n",
    "        self.ngf = ngf\n",
    "        self.nc = nc\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Camada Linear para mapear o vetor de entrada para um tamanho de 8x8xngf*8\n",
    "            nn.Linear(self.nz, self.ngf * 8 * 8 * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Redimensiona para (ngf*8) x 8 x 8\n",
    "            nn.Unflatten(1, (self.ngf * 8, 8, 8)),\n",
    "\n",
    "            # Convoluções transpostas para aumentar gradualmente a resolução\n",
    "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(True),         \n",
    "        \n",
    "            # Ajuste final: reduzir a última camada para não aumentar o tamanho da imagem\n",
    "            nn.ConvTranspose2d(self.ngf, self.nc, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.Tanh()  # Normaliza a saída entre [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=3, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "    \n",
    "        self.nc = nc\n",
    "        self.ndf = ndf\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Camada 1: Convolução com stride 2 reduz a imagem para (image_size/2) x (image_size/2)\n",
    "            nn.Conv2d(self.nc, self.ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Camada 2: Convolução com stride 2 reduz a imagem para (image_size/4) x (image_size/4)\n",
    "            nn.Conv2d(self.ndf, self.ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Camada 3: Convolução com stride 2 reduz a imagem para (image_size/8) x (image_size/8)\n",
    "            nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Camada 4: Convolução com stride 2 reduz a imagem para (image_size/16) x (image_size/16)\n",
    "            nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Camada final: Convolução com kernel de (2, 2) para reduzir a imagem para 1 x 1\n",
    "            nn.Conv2d(self.ndf * 8, 1, 2, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def asmape(y_true, y_pred, mask=None):\n",
    "    if mask is not None:\n",
    "         y_true, y_pred = y_true[mask==1], y_pred[mask==1]\n",
    "    if type(y_true) is list or type(y_pred) is list:\n",
    "         y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    len_ = len(y_true)\n",
    "    tmp = 100 * (np.nansum(np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))/len_)\n",
    "\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def validate(loader, netG, netD, device):\n",
    "    netG.eval()\n",
    "    netD.eval()\n",
    "    \n",
    "    total_loss_G = 0.0\n",
    "    total_loss_D = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for real_cpu, noise, _, _, masks in loader:\n",
    "            real_cpu = real_cpu.to(device)\n",
    "            noise = noise.to(device)\n",
    "            masks = masks.to(device)\n",
    "            masks = masks.view(-1, 1, 32, 32).float()  # Ajustar a máscara para o mesmo formato da imagem\n",
    "\n",
    "            # Aplicar máscara na imagem real\n",
    "            real_masked = real_cpu * masks  \n",
    "\n",
    "            # Gerar imagens falsas e aplicar a máscara\n",
    "            fake = netG(noise)\n",
    "            fake_masked = fake * masks  \n",
    "\n",
    "            # Avaliação do discriminador\n",
    "            output_real = netD(real_masked).view(-1)\n",
    "            output_fake = netD(fake_masked).view(-1)\n",
    "\n",
    "            # Calcular perdas\n",
    "            loss_D = discriminator_loss(output_real, output_fake)\n",
    "            loss_G = generator_loss(output_fake)\n",
    "\n",
    "            total_loss_D += loss_D.item()\n",
    "            total_loss_G += loss_G.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_loss_D = total_loss_D / num_batches\n",
    "    avg_loss_G = total_loss_G / num_batches\n",
    "    print(f'Validation Loss_D: {avg_loss_D:.4f} \\tValidation Loss_G: {avg_loss_G:.4f}')\n",
    "    \n",
    "    netG.train()\n",
    "    netD.train()\n",
    "    return avg_loss_G\n",
    "\n",
    "    \n",
    "# Funções de perda como exemplo\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    real_loss = criterion(real_output, torch.ones_like(real_output, device=real_output.device))\n",
    "    fake_loss = criterion(fake_output, torch.zeros_like(fake_output, device=fake_output.device))\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    return criterion(fake_output, torch.ones_like(fake_output, device=fake_output.device))\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, DEVICE):\n",
    "    # print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file,weights_only=True, map_location=DEVICE)  # Carrega o estado salvo\n",
    "    model.load_state_dict(checkpoint)  # Usa diretamente o dicionário de pesos\n",
    "    return model\n",
    "\n",
    "def test( gen, test_loader, taxa, fold, chanells):  \n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        df = pd.DataFrame([],columns=['mae','asmape','mape','rmse','scale'], index=test_loader.dataset.horse_images)\n",
    "        for (zebra, horse,std_val,mean_val, masks), name in zip(test_loader,test_loader.dataset.horse_images):\n",
    "        \n",
    "            zebra = zebra.to(device)\n",
    "            horse = horse.to(device)\n",
    "           \n",
    "            # Converter k e min_val para tensores, mas movê-los para GPU somente se necessário\n",
    "            std_val = torch.tensor(std_val) if not isinstance(std_val, torch.Tensor) else std_val\n",
    "            mean_val = torch.tensor(mean_val) if not isinstance(mean_val, torch.Tensor) else mean_val\n",
    "            \n",
    "            # Gerar fake_zebra usando o gerador\n",
    "            fake_zebra = gen(horse)\n",
    "         \n",
    "            # Mover apenas as imagens para CPU antes de operações subsequentes\n",
    "            zebra = zebra.cpu()\n",
    "            fake_zebra = fake_zebra.cpu()\n",
    "            \n",
    "             #Voltar para escala original \n",
    "            zebra = (zebra)*std_val + mean_val\n",
    "            fake_zebra = (fake_zebra)* std_val + mean_val\n",
    "\n",
    "             # Somar sobre o canal e achatar as imagens\n",
    "            zebra = torch.sum(zebra, dim=1).flatten()\n",
    "            fake_zebra = torch.sum(fake_zebra, dim=1).flatten()\n",
    "\n",
    "            # Calcular as métricas\n",
    "            zebra_np = zebra*masks\n",
    "            fake_zebra_np = fake_zebra*masks\n",
    "\n",
    "\t\t\t\t    # Calcular as métricas corretamente\n",
    "            mae_value = round(mae(zebra_np, fake_zebra_np), 3)\n",
    "            mape_value = round(mape(zebra_np, fake_zebra_np) * 100, 3)\n",
    "            rmse_value = round(np.sqrt(mse(zebra_np, fake_zebra_np)), 3)\n",
    "            smape_value = round(asmape(zebra_np, fake_zebra_np,masks), 3)\n",
    "            # Adicionar os resultados ao DataFram\n",
    "            df.loc[name] = [mae_value, smape_value, mape_value, rmse_value, np.max(zebra.numpy()) - np.min(zebra.numpy())]\n",
    "\n",
    "\t\t\t\t# Salva o DataFrame em um arquivo CSV\n",
    "        directory =  \"./resultados/resultados_dc\"\n",
    "        if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "        df.to_csv(rf'{directory}/result_{str(chanells)}c_{taxa}_{fold}.csv')\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "# import torch.multiprocessing as mp\n",
    "TRAIN_DIR = os.path.abspath(\"../dataset_final\")  \n",
    "VAL_DIR = os.path.abspath(\"../dataset_final\")  \n",
    "INDEX_TRAIN = os.path.abspath(\"../dataset_final\")  \n",
    "INDEX_VAL = os.path.abspath(\"../dataset_final\")  \n",
    "INDEX_TEST = os.path.abspath(\"../dataset_final\")  \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def main(in_channels):\n",
    "    \n",
    "    for taxa in ['10','20','30','40']:\n",
    "        for fold in ['1','2','3','4','5']:  \n",
    "        \n",
    "            test_dataset = LoaderDataset(\n",
    "                  root_zebra=os.path.join( VAL_DIR, \"label\", str(taxa), \"folds\", f\"fold{fold}\", \"test\"),\n",
    "\t\t\t\t\t\t\t\t\troot_horse=os.path.join( VAL_DIR, \"input\", str(taxa), \"folds\", f\"fold{fold}\", \"test\"),\n",
    "\t\t\t\t\t\t\t\t\troot_masks=os.path.join(INDEX_TEST, \"input\", str(taxa), \"folds\", f\"fold{fold}\", \"index\"),\n",
    "\t\t\t\t\t\t\t\t\tchanels=in_channels\n",
    "\t\t\t\t\t\t)\n",
    "            \n",
    "            test_loader = DataLoader(\n",
    "                    test_dataset,\n",
    "                    batch_size=1,\n",
    "                    shuffle=False,\n",
    "                    pin_memory=False )\n",
    "            \n",
    "            #Treino        \n",
    "           \n",
    "        \n",
    "            save_dir = f\"./models_saved/dcgan/{in_channels}/{taxa}/fold{fold}\"\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "                \n",
    "            # Salvar modelo\n",
    "            model_path = os.path.join(save_dir, \"generator.pth\")\n",
    "            generator = Generator(nz=in_channels*1024, nc=in_channels).to(device)\n",
    "\n",
    "            # Teste\n",
    "            \n",
    "            test(generator,test_loader=test_loader,taxa=taxa,fold=fold,chanells=in_channels)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "  # Necessário no Windows para compatibilidade\n",
    "    for i in [1,2,3]:\n",
    "        print(f'{i} channels: Iniciando o teste ....')\n",
    "        main(i)\n",
    "    total_time = time.time() - start_time\n",
    "    print(f'{total_time/3600} horas')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt_envmau",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
