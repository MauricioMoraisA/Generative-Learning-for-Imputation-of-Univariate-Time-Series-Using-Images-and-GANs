{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model ./models_saved/discogan/1/10/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/10/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/10/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/10/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/10/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/20/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/20/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/20/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/20/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/20/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/30/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/30/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/30/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/30/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/30/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/40/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/40/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/40/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/40/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/1/40/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/10/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/10/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/10/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/10/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/10/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/20/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/20/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/20/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/20/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/20/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/30/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/30/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/30/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/30/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/30/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/40/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/40/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/40/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/40/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/2/40/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/10/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/10/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/10/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/10/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/10/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/20/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/20/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/20/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/20/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/20/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/30/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/30/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/30/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/30/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/30/fold5/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/40/fold1/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/40/fold2/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/40/fold3/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/40/fold4/G_AB.pth\n",
      "\n",
      "\n",
      " Model ./models_saved/discogan/3/40/fold5/G_AB.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import time\n",
    "# import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# from torchvision.utils import save_image\n",
    "import sys \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def asmape(y_true, y_pred, mask=None):\n",
    "    if mask is not None:\n",
    "         y_true, y_pred = y_true[mask==1], y_pred[mask==1]\n",
    "    if type(y_true) is list or type(y_pred) is list:\n",
    "         y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    len_ = len(y_true)\n",
    "    tmp = 100 * (np.nansum(np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))/len_)\n",
    "\n",
    "    return tmp\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape, mean_absolute_error as mae, mean_squared_error as mse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "##############################\n",
    "#           U-NET\n",
    "##############################\n",
    "\n",
    "class LoaderDataset(Dataset):\n",
    "    def __init__(self, root_zebra, root_horse, root_masks, chanels=3):\n",
    "        self.root_zebra = root_zebra\n",
    "        self.root_horse = root_horse\n",
    "        self.root_index = root_masks\n",
    "        \n",
    "        self.zebra_images = sorted(os.listdir(root_zebra))\n",
    "        self.horse_images = sorted(os.listdir(root_horse))\n",
    "        self.index = sorted(os.listdir(root_masks))\n",
    "\n",
    "        self.length_dataset = max(len(self.zebra_images), len(self.horse_images))\n",
    "        self.zebra_len = len(self.zebra_images)\n",
    "        self.horse_len = len(self.horse_images)\n",
    "        self.index_len = len(self.index)\n",
    "        self.chanels = chanels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length_dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def custom_normalize(image):\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        min_val = torch.min(image)\n",
    "        max_val = torch.max(image)\n",
    "        scale = torch.clamp(max_val - min_val, min=1e-5)  # Evita divisÃ£o por zero\n",
    "        image_normalized = 2 * (image - min_val) / scale - 1  # Escala para [-1, 1]\n",
    "        return image_normalized, min_val, max_val\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        zebra_img = self.zebra_images[index % self.zebra_len]\n",
    "        horse_img = self.horse_images[index % self.horse_len]\n",
    "        index_ids = self.index[index % self.index_len]\n",
    "\n",
    "        zebra_path = os.path.join(self.root_zebra, zebra_img)\n",
    "        horse_path = os.path.join(self.root_horse, horse_img)\n",
    "        index_path = os.path.join(self.root_index, index_ids)\n",
    "        # print(zebra_path, horse_path, index_path)\n",
    "\n",
    "        zebra_img = np.load(zebra_path)\n",
    "        horse_img = np.load(horse_path)\n",
    "        mask = np.load(index_path)\n",
    "\n",
    "        if len(zebra_img.shape) > 3:\n",
    "            zebra_img = zebra_img.reshape(32, 32, 3)\n",
    "            horse_img = horse_img.reshape(32, 32, 3)\n",
    "\n",
    "        zebra_img = np.transpose(zebra_img, (2, 0, 1))\n",
    "        horse_img = np.transpose(horse_img, (2, 0, 1))\n",
    "\n",
    "        if self.chanels == 2:\n",
    "            zebra_img = zebra_img[:2, :, :]\n",
    "            horse_img = horse_img[:2, :, :]\n",
    "        elif self.chanels == 1:\n",
    "            zebra_img = np.sum(zebra_img, axis=0, keepdims=True)\n",
    "            horse_img = np.sum(horse_img, axis=0, keepdims=True)\n",
    "\n",
    "        zebra_img, min_val_z, max_val_z = LoaderDataset.custom_normalize(zebra_img)\n",
    "        horse_img, _, _ = LoaderDataset.custom_normalize(horse_img)\n",
    "\n",
    "        mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "        return zebra_img, horse_img, min_val_z, max_val_z, mask\n",
    "\n",
    "\n",
    "class ToFloat32:\n",
    "    def __call__(self, image, **kwargs):\n",
    "        return image.float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# === UNet Generator ===\n",
    "\n",
    "# === Instance Normalization Custom (como no TF) ===\n",
    "class InstanceNormalization(nn.Module):\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # escala e offset serÃ£o inicializados no forward com parÃ¢metros registrados\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x shape: (N,C,H,W)\n",
    "        mean = x.mean(dim=[2,3], keepdim=True)\n",
    "        var = x.var(dim=[2,3], keepdim=True, unbiased=False)\n",
    "        inv = 1.0 / torch.sqrt(var + self.epsilon)\n",
    "        normalized = (x - mean) * inv\n",
    "\n",
    "        # Criar escala e offset param se nÃ£o existirem\n",
    "        if not hasattr(self, 'scale'):\n",
    "            self.scale = nn.Parameter(torch.ones(x.size(1), device=x.device))\n",
    "            self.offset = nn.Parameter(torch.zeros(x.size(1), device=x.device))\n",
    "        # reshape para broadcast\n",
    "        scale = self.scale.view(1, -1, 1, 1)\n",
    "        offset = self.offset.view(1, -1, 1, 1)\n",
    "        return scale * normalized + offset\n",
    "\n",
    "\n",
    "\n",
    "# === Downsample e Upsample ===\n",
    "def downsample(in_ch, out_ch, norm_type='instancenorm', apply_norm=True):\n",
    "    layers = [nn.Conv2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False)]\n",
    "    if apply_norm:\n",
    "        if norm_type == 'batchnorm':\n",
    "            layers.append(nn.BatchNorm2d(out_ch))\n",
    "        elif norm_type == 'instancenorm':\n",
    "            layers.append(InstanceNormalization())\n",
    "    layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def upsample(in_ch, out_ch, norm_type='instancenorm', apply_dropout=False):\n",
    "    layers = [nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False)]\n",
    "    if norm_type == 'batchnorm':\n",
    "        layers.append(nn.BatchNorm2d(out_ch))\n",
    "    elif norm_type == 'instancenorm':\n",
    "        layers.append(InstanceNormalization())\n",
    "    layers.append(nn.ReLU(inplace=True))\n",
    "    if apply_dropout:\n",
    "        layers.append(nn.Dropout(0.5))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3, norm_type='instancenorm', target_size=256):\n",
    "        super().__init__()\n",
    "        self.target_size = target_size\n",
    "        self.down1 = downsample(input_channels, 64, norm_type, apply_norm=False)\n",
    "        self.down2 = downsample(64, 128, norm_type)\n",
    "        self.down3 = downsample(128, 256, norm_type)\n",
    "        self.down4 = downsample(256, 512, norm_type)\n",
    "        self.down5 = downsample(512, 512, norm_type)\n",
    "        self.down6 = downsample(512, 512, norm_type)\n",
    "        self.down7 = downsample(512, 512, norm_type)\n",
    "        self.down8 = downsample(512, 512, norm_type)\n",
    "\n",
    "        self.up1 = upsample(512, 512, norm_type, apply_dropout=True)\n",
    "        self.up2 = upsample(1024, 512, norm_type, apply_dropout=True)\n",
    "        self.up3 = upsample(1024, 512, norm_type, apply_dropout=True)\n",
    "        self.up4 = upsample(1024, 512, norm_type)\n",
    "        self.up5 = upsample(1024, 256, norm_type)\n",
    "        self.up6 = upsample(512, 128, norm_type)\n",
    "        self.up7 = upsample(256, 64, norm_type)\n",
    "\n",
    "        self.final = nn.ConvTranspose2d(128, output_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        orig_size = x.shape[-2:]  # (H, W)\n",
    "\n",
    "        # Upsample entrada para target_size x target_size\n",
    "        x = F.interpolate(x, size=(self.target_size, self.target_size), mode='bilinear', align_corners=False)\n",
    "\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "\n",
    "        u1 = self.up1(d8)\n",
    "        u1 = torch.cat([u1, d7], dim=1)\n",
    "\n",
    "        u2 = self.up2(u1)\n",
    "        u2 = torch.cat([u2, d6], dim=1)\n",
    "\n",
    "        u3 = self.up3(u2)\n",
    "        u3 = torch.cat([u3, d5], dim=1)\n",
    "\n",
    "        u4 = self.up4(u3)\n",
    "        u4 = torch.cat([u4, d4], dim=1)\n",
    "\n",
    "        u5 = self.up5(u4)\n",
    "        u5 = torch.cat([u5, d3], dim=1)\n",
    "\n",
    "        u6 = self.up6(u5)\n",
    "        u6 = torch.cat([u6, d2], dim=1)\n",
    "\n",
    "        u7 = self.up7(u6)\n",
    "        u7 = torch.cat([u7, d1], dim=1)\n",
    "\n",
    "        output = self.final(u7)\n",
    "        output = self.tanh(output)\n",
    "\n",
    "        # Downsample a saÃ­da para o tamanho original da entrada\n",
    "        output = F.interpolate(output, size=orig_size, mode='bilinear', align_corners=False)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "def test(gen_Z, test_loader, taxa, fold, chanells):\n",
    "\t\tDEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\t\tgen_Z.eval()\n",
    "\t\t\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# Criar o DataFrame com as colunas desejadas\n",
    "\t\t\tdf = pd.DataFrame([], columns=['mae', 'asmape', 'mape', 'rmse', 'scale'], index=test_loader.dataset.horse_images)\n",
    "\n",
    "\t\t\tfor (zebra, horse, std_val, mean_val, masks), name in zip(test_loader, test_loader.dataset.horse_images):\n",
    "\t\t\t\t\t# Verificar as dimensÃµes das entradas\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Mover dados para o dispositivo\n",
    "\t\t\t\t\tzebra = zebra.to(DEVICE)\n",
    "\t\t\t\t\thorse = horse.to(DEVICE)\n",
    "\n",
    "\t\t\t\t\t# Converter std_val e mean_val para tensores e movÃª-los para o dispositivo\n",
    "\t\t\t\t\tstd_val = torch.tensor(std_val, device=DEVICE) if not isinstance(std_val, torch.Tensor) else std_val.to(DEVICE)\n",
    "\t\t\t\t\tmean_val = torch.tensor(mean_val, device=DEVICE) if not isinstance(mean_val, torch.Tensor) else mean_val.to(DEVICE)\n",
    "\n",
    "\t\t\t\t\t# Gerar fake_zebra usando o gerador\n",
    "\t\t\t\t\tfake_zebra = gen_Z(horse)\n",
    "\n",
    "\t\t\t\t\t# Mover apenas as imagens para a CPU antes de operaÃ§Ãµes subsequentes\n",
    "\t\t\t\t\tzebra = zebra.cpu()\n",
    "\t\t\t\t\tfake_zebra = fake_zebra.cpu()\n",
    "\n",
    "\t\t\t\t\t# Voltar para escala original \n",
    "\t\t\t\t\tzebra = zebra * std_val.cpu() + mean_val.cpu()\n",
    "\t\t\t\t\tfake_zebra = fake_zebra * std_val.cpu() + mean_val.cpu()\n",
    "\n",
    "\t\t\t\t\t# Somar sobre o canal e achatar as imagens\n",
    "\t\t\t\t\tzebra = torch.sum(zebra, dim=1).flatten()*masks\n",
    "\t\t\t\t\tfake_zebra = torch.sum(fake_zebra, dim=1).flatten()*masks\n",
    "\n",
    "\t\t\t\t\t# Calcular as mÃ©tricas\n",
    "\t\t\t\t\tmae_value = round(mae(zebra, fake_zebra), 3)\n",
    "\t\t\t\t\tmape_value = round(mape(zebra, fake_zebra) * 100, 3)\n",
    "\t\t\t\t\trmse_value = round(np.sqrt(mse(zebra, fake_zebra)), 3)\n",
    "\t\t\t\t\tsmape_value = round(asmape(zebra, fake_zebra, masks), 3)\n",
    "\n",
    "\t\t\t\t\t# Adicionar os resultados ao DataFrame\n",
    "\t\t\t\t\tdf.loc[name] = [mae_value,smape_value , mape_value, rmse_value, np.max(zebra.numpy()) - np.min(zebra.numpy())]\n",
    "\n",
    "\t\t\t# Salvar o DataFrame em um arquivo CSV\n",
    "\t\t\tdirectory = \"./resultados/resultados_discogan\"\n",
    "\t\t\tif not os.path.exists(directory):\n",
    "\t\t\t\t\tos.makedirs(directory)\n",
    "\n",
    "\t\t\tdf.to_csv(os.path.join(directory, f'result_{str(chanells)}c_{taxa}_{fold}.csv'))\n",
    "\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, DEVICE):\n",
    "    # print(\"=> Loading checkpoint\")\n",
    "   state_dict = torch.load(checkpoint_file, map_location=DEVICE, weights_only=True)\n",
    "   model.load_state_dict(state_dict)\n",
    "   return model\n",
    "\n",
    "# ----------\n",
    "#  Treinamento\n",
    "# ----------\n",
    "# ParÃ¢metros de treinamento\n",
    "\n",
    "TRAIN_DIR = os.path.abspath(\"../dataset_final\")  \n",
    "VAL_DIR = os.path.abspath(\"../dataset_final\")  \n",
    "INDEX_TRAIN = os.path.abspath(\"../dataset_final\")  \n",
    "INDEX_VAL = os.path.abspath(\"../dataset_final\")  \n",
    "INDEX_TEST = os.path.abspath(\"../dataset_final\")    \n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "lrd= 1e-4\n",
    "lrg= 1e-3\n",
    "b1 =0.5\n",
    "b2= 0.999\n",
    "               \n",
    "def main(in_channels):\n",
    "\tfor taxa in ['10','20','30','40']:\n",
    "\t\t\tfor fold in ['1','2','3','4','5']:\n",
    "\t\t\t\t\t# Perdas\n",
    "\t\t\t\t\tadversarial_loss = torch.nn.MSELoss()\n",
    "\t\t\t\t\tcycle_loss = torch.nn.L1Loss()\n",
    "\t\t\t\t\tpixelwise_loss = torch.nn.L1Loss()\n",
    "\n",
    "\t\t\t\t\tcuda =  \"cuda:0\" if torch.cuda.is_available() else \"cpu\" #torch.cuda.is_available()\n",
    "\n",
    "\t\t\t\t\tinput_shape = (in_channels, 32, 32)\n",
    "\n",
    "\t\t\t\t\t# Inicializar geradores e discriminadores\n",
    "\t\t\t\n",
    "\t\t\t\t\tG_BA = UNetGenerator(input_channels=in_channels, output_channels=in_channels, norm_type='instancenorm')\n",
    "\t\t\t\t\tG_BA.to(cuda)\n",
    "\t\t\t\t\tdummy_in = torch.zeros(1, in_channels, G_BA.target_size, G_BA.target_size, device=cuda)\n",
    "\t\t\t\t\t_ = G_BA(dummy_in)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\t\n",
    "\t\n",
    "\t\t\t\t\ttest_dataset = LoaderDataset(\n",
    "\t\t\t\t\t\t\t\troot_zebra=os.path.join( VAL_DIR, \"label\", str(taxa), \"folds\", f\"fold{fold}\", \"test\"),\n",
    "\t\t\t\t\t\t\t\troot_horse=os.path.join( VAL_DIR, \"input\", str(taxa), \"folds\", f\"fold{fold}\", \"test\"),\n",
    "\t\t\t\t\t\t\t\troot_masks=os.path.join(INDEX_TEST, \"input\", str(taxa), \"folds\", f\"fold{fold}\", \"index\"),\n",
    "\t\t\t\t\t\t\t\tchanels=in_channels\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t\t\ttest_loader = DataLoader( test_dataset,  batch_size=1,shuffle=False,pin_memory=False )\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\ttest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "\t\t\t\t\tprev_time = time.time()\n",
    "\n",
    "\t\t\t\t\tbest_val_loss = float('inf')\n",
    "\n",
    "\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\tsave_dir = f\"./models_saved/discogan/{in_channels}/{taxa}/fold{fold}\"\n",
    "\t\t\t\t\tif not os.path.exists(save_dir):\n",
    "\t\t\t\t\t\tos.makedirs(save_dir)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t# Salvar modelo\n",
    "\t\t\t\t\tmodel_path = os.path.join(save_dir, \"G_AB.pth\")\n",
    "\t\t\t\t\tload_checkpoint(model_path,G_BA,cuda)\n",
    "\t\t\t\t\tprint(f\"\\n Model {model_path}\\n\")\n",
    "\t\t\t\t\t# Teste apÃ³s cada Ã©poca\n",
    "\t\t\t\t\ttest(G_BA, test_loader, taxa, fold, in_channels)\n",
    "\t\t\t\t\tG_BA.train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for i in [1,2,3]:\n",
    "        main(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt_envmau",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
